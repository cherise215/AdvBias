{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Finding effective adversarial bias field for data augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import math\n",
    "import torch\n",
    "\n",
    "from common.utils import get_unet_model\n",
    "from augmentor.adv_bias import AdvBias\n",
    "from common.utils import _disable_tracking_bn_stats,set_grad\n",
    "from augmentor.adv_compose_solver import ComposeAdversarialTransformSolver\n",
    "from common.loss import cross_entropy_2D"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common.common'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a077183daf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_unet_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_disable_tracking_bn_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_compose_solver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComposeAdversarialTransformSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common.common'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. 1 Load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_path ='./data/img.nrrd'\n",
    "label_path ='./data/seg.nrrd'\n",
    "\n",
    "image = sitk.GetArrayFromImage(sitk.ReadImage(image_path))\n",
    "label = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "\n",
    "print ('image size:',image.shape)\n",
    "print ('label size:',label.shape)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.2 Preprocessing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## central crop them to [128,128]\n",
    "crop_size =(128,128)\n",
    "h_diff = (image.shape[1]-crop_size[0])//2\n",
    "w_diff = (image.shape[2]-crop_size[1])//2\n",
    "\n",
    "cropped_images = image[:,h_diff:crop_size[0]+h_diff,w_diff:crop_size[1]+w_diff]\n",
    "cropped_labels = label[:,h_diff:crop_size[0]+h_diff,w_diff:crop_size[1]+w_diff]\n",
    "\n",
    "cropped_labels[cropped_labels==1]=0\n",
    "cropped_labels[cropped_labels==3]=0\n",
    "cropped_labels[cropped_labels==2]=1\n",
    "\n",
    "# rescale image intensities to 0-1\n",
    "cropped_images = (cropped_images-cropped_images.min())/(cropped_images.max()-cropped_images.min()+1e-10)\n",
    "cropped_images.shape\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "slice_id=7\n",
    "font_size=12\n",
    "plt.subplot(121)\n",
    "plt.title('image',size=font_size)\n",
    "plt.imshow(cropped_images[slice_id],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(cropped_labels[slice_id],cmap='gray')\n",
    "plt.title('manual label',size=font_size)\n",
    "plt.axis('off')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.1 Load a segmentation model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "use_gpu=True\n",
    "model = get_unet_model(num_classes=2,model_path='./saved_checkpoints/myo_seg_unet_16.pth',model_arch='UNet_16')\n",
    "if use_gpu: \n",
    "    model = model.cuda()\n",
    "model.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_tensor = torch.from_numpy(cropped_images[:,np.newaxis,:,:]).float()\n",
    "target_tensor = torch.from_numpy(cropped_labels).long()\n",
    "\n",
    "if use_gpu: \n",
    "    image_tensor = image_tensor.cuda()\n",
    "    target_tensor = target_tensor.cuda()\n",
    "\n",
    "image_tensor.requires_grad=False\n",
    "target_tensor.requires_grad=False\n",
    "\n",
    "with torch.no_grad():\n",
    "    init_output = model(image_tensor)\n",
    "pred_map = init_output.max(1)[1].cpu().data.numpy()\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('image',size=font_size)\n",
    "plt.imshow(cropped_images[slice_id],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(cropped_labels[slice_id],cmap='gray')\n",
    "plt.title('manual label',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.imshow(pred_map[slice_id],cmap='gray')\n",
    "plt.title('init pred',size=font_size)\n",
    "plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2.2 Set up  bias field configurations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "augmentor_bias= AdvBias(\n",
    "                 config_dict={'epsilon':0.3, ## magnitude constraints\n",
    "                 'control_point_spacing':[crop_size[0]//4,crop_size[1]//4], \n",
    "                 'downscale':2,\n",
    "                 ## the true spacing should be 2*crop_size[0]//4, 2*crop_size[0]//4] as we downscale the image by a factor of 2 for acceleration\n",
    "                 'data_size':[image_tensor.size(0),image_tensor.size(1),image_tensor.size(2),image_tensor.size(3)],\n",
    "                 'interpolation_order':3,\n",
    "                 'init_mode':'random',\n",
    "                 'space':'log'},debug=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3 Perform random bias field augmentation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "augmentor_bias.init_parameters()\n",
    "rand_biased_image_tensor = augmentor_bias.forward(image_tensor) \n",
    "with _disable_tracking_bn_stats(model):\n",
    "    rand_pred_map = model(rand_biased_image_tensor.detach().clone()).max(1)[1].cpu().data.numpy()\n",
    "perturbed_image =rand_biased_image_tensor.cpu().numpy()\n",
    "rand_bias= augmentor_bias.bias_field.cpu().numpy()\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.title('image',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(cropped_images[slice_id],cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('perturbed',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(perturbed_image[slice_id,0],cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('rand bias',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(rand_bias[slice_id,0],cmap='jet')\n",
    "plt.subplot(234)\n",
    "plt.imshow(pred_map[slice_id],cmap='gray')\n",
    "plt.title('before',size=font_size)\n",
    "plt.subplot(235)\n",
    "plt.imshow(rand_pred_map[slice_id],cmap='gray')\n",
    "plt.title('after',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.subplot(236)\n",
    "plt.imshow(abs(rand_pred_map[slice_id]-pred_map[slice_id]),cmap='gray')\n",
    "plt.title('diff',size=font_size)\n",
    "plt.axis('off')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.1 Set up learner to optimize bias field "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "solver = ComposeAdversarialTransformSolver(\n",
    "        chain_of_transforms=[augmentor_bias],\n",
    "        divergence_types = ['kl','contour'], ### you can also change it to 'mse' for mean squared error loss\n",
    "        divergence_weights=[1.0,0.5],\n",
    "        use_gpu= True,\n",
    "        debug=True,\n",
    "       )\n",
    "\n",
    "## 4. start learning\n",
    "solver.init_random_transformation()\n",
    "rand_transformed_image = solver.forward(image_tensor.detach().clone())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4.2 Apply adversarial data augmentation for network training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "solver = ComposeAdversarialTransformSolver(\n",
    "        chain_of_transforms=[augmentor_bias],\n",
    "        divergence_types = ['kl','contour'], ### you can also change it to 'mse' for mean squared error loss\n",
    "        divergence_weights=[1.0,0.5],\n",
    "        use_gpu= True,\n",
    "        debug=True,\n",
    "       )\n",
    "\n",
    "## 4. start learning\n",
    "solver.init_random_transformation()\n",
    "rand_transformed_image = solver.forward(image_tensor.detach().clone())\n",
    "with _disable_tracking_bn_stats(model):\n",
    "        rand_predict = model.forward(rand_transformed_image)\n",
    "rand_bias = augmentor_bias.bias_field\n",
    "\n",
    "model.zero_grad()\n",
    "## 4.2 adv data augmentation \n",
    "loss = solver.adversarial_training(\n",
    "        data=image_tensor,model=model,\n",
    "        n_iter=1,\n",
    "        lazy_load=[True], ## if set to true, it will use the previous sampled random bias field as initialization.\n",
    "        optimize_flags=[True],power_iteration=False)\n",
    "\n",
    "adv_bias= augmentor_bias.bias_field\n",
    "\n",
    "adv_transformed_image = solver.forward(image_tensor.detach().clone())\n",
    "adv_predict = model.forward(adv_transformed_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rand_transformed_image_numpy=rand_transformed_image.cpu().data.numpy()[slice_id,0]\n",
    "adv_transformed_image_numpy=adv_transformed_image.cpu().data.numpy()[slice_id,0]\n",
    "\n",
    "rand_predict_numpy=rand_predict.max(1)[1].cpu().data.numpy()[slice_id]\n",
    "adv_predict_numpy=adv_predict.max(1)[1].cpu().data.numpy()[slice_id]\n",
    "\n",
    "rand_bias_numpy=rand_bias.cpu().data.numpy()[slice_id,0]\n",
    "adv_bias_numpy=adv_bias.cpu().data.numpy()[slice_id,0]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(461)\n",
    "plt.title('image',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(cropped_images[slice_id],cmap='gray')\n",
    "plt.subplot(462)\n",
    "plt.title('perturbed',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(rand_transformed_image_numpy,cmap='gray')\n",
    "plt.subplot(463)\n",
    "plt.imshow(rand_bias_numpy,cmap='jet')\n",
    "plt.title('rand bias',size=font_size)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(464)\n",
    "plt.title('before',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(pred_map[slice_id],cmap='gray')\n",
    "plt.subplot(465)\n",
    "plt.title('after',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(rand_predict_numpy,cmap='gray')\n",
    "plt.subplot(466)\n",
    "plt.imshow(abs(rand_predict_numpy-pred_map[slice_id]),cmap='gray')\n",
    "plt.title('diff',size=font_size)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(467)\n",
    "plt.title('image',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(cropped_images[slice_id],cmap='gray')\n",
    "plt.subplot(468)\n",
    "plt.title('perturbed',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(adv_transformed_image_numpy,cmap='gray')\n",
    "plt.subplot(469)\n",
    "plt.imshow(adv_bias_numpy,cmap='jet')\n",
    "plt.title('adv bias',size=font_size)\n",
    "plt.axis('off')\n",
    "## results with adv bias field\n",
    "\n",
    "plt.subplot(4,6,10)\n",
    "plt.title('before',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(pred_map[slice_id],cmap='gray')\n",
    "plt.subplot(4,6,11)\n",
    "plt.title('after',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.imshow(adv_predict_numpy,cmap='gray')\n",
    "plt.subplot(4,6,12)\n",
    "plt.imshow(abs(adv_predict_numpy-pred_map[slice_id]),cmap='gray')\n",
    "plt.title('diff',size=font_size)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## now you can simply learn effective adversarial bias fields on-the-fly to enhance training. a sample code will be like the following\n",
    "## pseudo code for model optimization at one iteration: \n",
    "solver = ComposeAdversarialTransformSolver(\n",
    "         chain_of_transforms=[augmentor_bias],\n",
    "        divergence_types = ['kl','contour'], ### you can also change it to 'mse' for mean squared error loss\n",
    "        divergence_weights=[1.0,0.5],\n",
    "        use_gpu= use_gpu,\n",
    "        debug=True, ## turn off debugging information\n",
    "       )\n",
    "\n",
    "## unsupervised consistency loss\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "model.train()\n",
    "reg_loss = solver.adversarial_training(\n",
    "        data=image_tensor.detach().clone(),model=model,\n",
    "        n_iter=1,\n",
    "        lazy_load=[False], \n",
    "        optimize_flags=[True],power_iteration=[False])\n",
    "## you can add it with the your original supervised loss (if have one). Below is a demo code for reference\n",
    "with torch.enable_grad():\n",
    "        pred = model(image_tensor)\n",
    "        \n",
    "supervised_loss = cross_entropy_2D(pred,target_tensor)\n",
    "lamda=1\n",
    "total_loss = supervised_loss+lamda*reg_loss\n",
    "print ('supervised loss:',total_loss.item())\n",
    "total_loss.backward()\n",
    "optimizer.step() \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5 Extension: generate 3D bias field augmentation (for fun)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## test 3D bias field augmentation (under development)\n",
    "from augmentor.adv_bias_3d import AdvBias3D\n",
    "\n",
    "image_tensor_5d = torch.from_numpy(cropped_images[np.newaxis,np.newaxis,:,:,:]).float() ## [bs,ch,d,h,w]\n",
    "if use_gpu: \n",
    "  image_tensor_5d = image_tensor_5d.to(torch.device('cuda'))\n",
    "image_tensor_5d.requires_grad=False\n",
    "print ('input:',image_tensor_5d.size())\n",
    "bias_field_augmentor3d= AdvBias3D(\n",
    "               config_dict= {'epsilon':0.9, \n",
    "                 'control_point_spacing':[16,16,16],\n",
    "                 'downscale':4, ## increase the downscale factor to save interpolation time\n",
    "                 'data_size':[*image_tensor_5d.size()],\n",
    "                 'interpolation_order':3,\n",
    "                 'init_mode':'random',\n",
    "                 'space':'log'},\n",
    "        power_iteration=False,\n",
    "        debug=True,use_gpu=use_gpu)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Augmenting 3D "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_tensor_5d = image_tensor_5d.to(torch.device('cuda'))\n",
    "bias_field_augmentor3d.init_parameters()\n",
    "augmented_image=bias_field_augmentor3d.forward(image_tensor_5d)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "slice_id= 1\n",
    "image_numpy= image_tensor_5d.cpu().data.numpy()\n",
    "augmented_image_numpy= augmented_image.cpu().data.numpy()\n",
    "plt.subplot(131)\n",
    "plt.imshow(image_numpy[0,0,slice_id],cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('before')\n",
    "plt.subplot(132)\n",
    "plt.axis('off')\n",
    "plt.title('after')\n",
    "plt.imshow(augmented_image_numpy[0,0,slice_id],cmap='gray')\n",
    "plt.subplot(133)\n",
    "plt.title('diff')\n",
    "plt.axis('off')\n",
    "plt.imshow(augmented_image_numpy[0,0,slice_id]-image_numpy[0,0,slice_id],cmap='seismic')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('new_benchmark': conda)"
  },
  "interpreter": {
   "hash": "62ce74b4455b0951965d257e46d77b8a88c22ef06fc866aa0e581269e0bc2661"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}